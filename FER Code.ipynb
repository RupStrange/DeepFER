{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vncDsAP0Gaoa"
   },
   "source": [
    "# **Project Name**    - DeepFER: Facial Emotion Recognition Using Deep Learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3lxredqlCYt"
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8X4HqYmPi00B"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "M8Vqi-pPk-HR"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrandom\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Flatten, Dense,\n",
    "                                     Dropout, BatchNormalization)\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RnN4peoiCZX"
   },
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4CkvbW_SlZ_R"
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "base_dataset_path = 'original_images'\n",
    "\n",
    "train_data_dir = os.path.join(base_dataset_path, 'train')\n",
    "validation_data_dir = os.path.join(base_dataset_path, 'validation')\n",
    "print(train_data_dir)\n",
    "print(validation_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x71ZqKXriCWQ"
   },
   "source": [
    "### Dataset First View"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-iBbQFdi00C"
   },
   "source": [
    "#### Viewing images from Training Images Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWNFOSvLl09H"
   },
   "outputs": [],
   "source": [
    "# Dataset First Look\n",
    "train_path = 'original_images/train'\n",
    "train_classes = os.listdir(train_path)\n",
    "\n",
    "for class_name in train_classes:\n",
    "    class_dir = os.path.join(train_path, class_name)\n",
    "    images_files = os.listdir(class_dir)\n",
    "\n",
    "    print(f\"5 random Images in the {class_name} folder out of {len(images_files)} total files\")\n",
    "\n",
    "    random_images = random.sample(images_files, min(5, len(images_files)))\n",
    "\n",
    "    plt.figure(figsize = (15, 3))\n",
    "    for index, images in enumerate(random_images):\n",
    "        img_path = os.path.join(class_dir, images)\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        plt.subplot(1, 5, index+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(class_name)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "gCr3z4xTi00D",
    "tags": []
   },
   "source": [
    "#### Viewing images from Validation Images Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pSA-LVRJi00D"
   },
   "outputs": [],
   "source": [
    "# Validation Dataset First Look\n",
    "val_path = 'original_images/validation'\n",
    "val_classes = os.listdir(val_path)\n",
    "\n",
    "for class_name in val_classes:\n",
    "    class_dir = os.path.join(val_path, class_name)\n",
    "    images_files = os.listdir(class_dir)\n",
    "\n",
    "    print(f\"5 random Images in the {class_name} folder out of {len(images_files)} total files\")\n",
    "\n",
    "    random_images = random.sample(images_files, min(5, len(images_files)))\n",
    "\n",
    "    plt.figure(figsize = (15, 3))\n",
    "    for index, images in enumerate(random_images):\n",
    "        img_path = os.path.join(class_dir, images)\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        plt.subplot(1, 5, index+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(class_name)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hBIi_osiCS2"
   },
   "source": [
    "### Images Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kllu7SJgmLij"
   },
   "outputs": [],
   "source": [
    "main_dir = 'original_images'\n",
    "main_dir_files = os.listdir(main_dir)\n",
    "for sub_dir in main_dir_files:\n",
    "    class_dir = os.path.join(main_dir, sub_dir)\n",
    "    class_dir_files = os.listdir(class_dir)\n",
    "    print(\"-\"*90)\n",
    "    print(f\"Folder inside {sub_dir}: {class_dir_files}\")\n",
    "    print(f\"Total Classes in the {sub_dir} folder is: {len(class_dir_files)}\")\n",
    "\n",
    "    total_images = 0\n",
    "    for files in class_dir_files:\n",
    "        files_dir  =  os.path.join(class_dir, files)\n",
    "        images_count = len(os.listdir(files_dir))\n",
    "        total_images+=images_count\n",
    "        print(f\"Count of images inside {files} : {images_count}\")\n",
    "    print()\n",
    "    print(f\"Total images in {sub_dir} Folder : {total_images}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlHwYmJAmNHm"
   },
   "source": [
    "### Dataset Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35m5QtbWiB9F"
   },
   "source": [
    "#### Duplicate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1sLdpKYkmox0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "\n",
    "def md5_hasher(file_path):\n",
    "    hasher = hashlib.md5()\n",
    "    with open(file_path, 'rb') as f:\n",
    "        file = f.read()\n",
    "        hasher.update(file)\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "# Function to find duplicate images\n",
    "def find_duplicates(folder_path):\n",
    "    hashes = {}\n",
    "    duplicates = []\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                file_hash = md5_hasher(file_path)\n",
    "\n",
    "                if file_hash in hashes:\n",
    "                    duplicates.append((file_path, hashes[file_hash]))\n",
    "                else:\n",
    "                    hashes[file_hash] = file_path\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "    return duplicates\n",
    "\n",
    "dups = find_duplicates('original_images')\n",
    "print(f\"Total duplicate files found: {len(dups)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wYPkZDgei00E"
   },
   "outputs": [],
   "source": [
    "# Randomly sample up to 5 duplicate pairs\n",
    "random_images = random.sample(dups, min(5, len(dups)))\n",
    "\n",
    "for dup_path, original_path in random_images:\n",
    "    try:\n",
    "        dup_img = Image.open(dup_path)\n",
    "        orig_img = Image.open(original_path)\n",
    "\n",
    "        plt.figure(figsize=(4, 2))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(dup_img)\n",
    "        plt.title(\"Duplicate\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(orig_img)\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.suptitle(\"Duplicate vs Original\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not open images: {dup_path}, {original_path} ‚Üí {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "joM1rnCni00E",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "\n",
    "# Function to calculate the MD5 hash of a file\n",
    "def md5_hasher(file_path):\n",
    "    hasher = hashlib.md5()\n",
    "    with open(file_path, 'rb') as f:\n",
    "        file_data = f.read()\n",
    "        hasher.update(file_data)\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "# Function to find duplicates across all folders and classes\n",
    "def find_duplicates_with_classes(folder_path):\n",
    "    hashes = {}\n",
    "    duplicates = []\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                file_hash = md5_hasher(file_path)\n",
    "\n",
    "                class_name = os.path.basename(os.path.dirname(file_path))\n",
    "\n",
    "                if file_hash in hashes:\n",
    "                    original_path = hashes[file_hash]['path']\n",
    "                    original_class = hashes[file_hash]['class']\n",
    "\n",
    "                    duplicates.append({\n",
    "                        'duplicate_path': file_path,\n",
    "                        'duplicate_class': class_name,\n",
    "                        'original_path': original_path,\n",
    "                        'original_class': original_class\n",
    "                    })\n",
    "                else:\n",
    "                    hashes[file_hash] = {'path': file_path, 'class': class_name}\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "    return duplicates\n",
    "\n",
    "\n",
    "duplicates = find_duplicates_with_classes('original_images')\n",
    "\n",
    "# Print results\n",
    "print(f\"Total duplicate files found: {len(duplicates)}\\n\")\n",
    "\n",
    "duplicates_different_classes = 0\n",
    "for dup in duplicates:\n",
    "    if dup['duplicate_class'] != dup['original_class']:\n",
    "        duplicates_different_classes+=1\n",
    "        print(f\"Duplicate Image : {dup['duplicate_path']} (Class: {dup['duplicate_class']})\")\n",
    "        print(f\"Original Image  : {dup['original_path']} (Class: {dup['original_class']})\")\n",
    "print()\n",
    "print(\"-\"*90)\n",
    "print(\"Total Number of duplicates with different classes :\", duplicates_different_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PoPl-ycgm1ru"
   },
   "source": [
    "#### Corrupt Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GgHWkxvamxVg"
   },
   "outputs": [],
   "source": [
    "# Missing Values/Null Values Count\n",
    "from PIL import Image\n",
    "\n",
    "def check_missing_or_corrupt_images(directory):\n",
    "    corrupt_images = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            path = os.path.join(root, file)\n",
    "            try:\n",
    "                img = Image.open(path)\n",
    "                img.verify()\n",
    "            except:\n",
    "                corrupt_images.append(path)\n",
    "\n",
    "    print(f\"Corrupt or Unreadable Images: {len(corrupt_images)}\")\n",
    "    return corrupt_images\n",
    "\n",
    "# Check both train and validation sets\n",
    "corrupt_train = check_missing_or_corrupt_images(train_data_dir)\n",
    "corrupt_val = check_missing_or_corrupt_images(validation_data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKXrzUCNi00G"
   },
   "source": [
    "##### Removing the duplicate images from the preprocessed folder which is the copy of the original images folder. It is done to ensure that the initial set of images remain untouched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ThPc_aqi00G"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "\n",
    "def md5_hasher(file_path):\n",
    "    hasher = hashlib.md5()\n",
    "    with open(file_path, 'rb') as f:\n",
    "        file = f.read()\n",
    "        hasher.update(file)\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "# Function to find duplicate images\n",
    "def find_duplicates(folder_path):\n",
    "    hashes = {}\n",
    "    duplicates = []\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                file_hash = md5_hasher(file_path)\n",
    "\n",
    "                if file_hash in hashes:\n",
    "                    duplicates.append((file_path, hashes[file_hash]))\n",
    "                else:\n",
    "                    hashes[file_hash] = file_path\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "    return duplicates\n",
    "\n",
    "dups = find_duplicates('preprocessed_images')\n",
    "print(f\"Total duplicate files found: {len(dups)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XY9XvLdbi00G",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ‚úÖ Delete duplicates\n",
    "for dup in dups:\n",
    "    duplicate_file = dup[0]\n",
    "\n",
    "    if os.path.exists(duplicate_file):\n",
    "        try:\n",
    "            os.remove(duplicate_file)\n",
    "            print(f\"‚úÖ Deleted: {duplicate_file}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {duplicate_file}: {e}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"File already deleted or not found: {duplicate_file}\")\n",
    "\n",
    "print(\"\\n‚úÖ All duplicate images deletion check completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12u6X2AKi00N"
   },
   "source": [
    "##### Comparison before and after deleting the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJrduG8-i00N"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "\n",
    "def count_images(main_dir, phase):\n",
    "    main_dir_files = os.listdir(main_dir)\n",
    "    for sub_dir in main_dir_files:\n",
    "        class_dir = os.path.join(main_dir, sub_dir)\n",
    "        class_dir_files = os.listdir(class_dir)\n",
    "\n",
    "        total_images_in_folder = 0\n",
    "\n",
    "        for files in class_dir_files:\n",
    "            files_dir = os.path.join(class_dir, files)\n",
    "            images_count = len(os.listdir(files_dir))\n",
    "\n",
    "            total_images_in_folder += images_count\n",
    "\n",
    "            data.append({\n",
    "                'Main Folder': sub_dir,\n",
    "                'Class': files,\n",
    "                'Images Count': images_count,\n",
    "                'Phase': phase\n",
    "            })\n",
    "\n",
    "        # ‚úÖ Append total count for the folder\n",
    "        data.append({\n",
    "            'Main Folder': sub_dir,\n",
    "            'Class': 'Total',\n",
    "            'Images Count': total_images_in_folder,\n",
    "            'Phase': phase\n",
    "        })\n",
    "\n",
    "count_images('original_images', 'Before')\n",
    "count_images('preprocessed_images', 'After')\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "comparison_df = df.pivot_table(index=['Main Folder', 'Class'],\n",
    "                               columns='Phase',\n",
    "                               values='Images Count',\n",
    "                               fill_value=0).reset_index()\n",
    "comparison_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHJ32w_ri00O"
   },
   "source": [
    "##### Unique data type of files found inside the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VKdHaONbi00O"
   },
   "outputs": [],
   "source": [
    "# checking the unique file formats i have in these folders\n",
    "def check_unique_file_formats(folder_path):\n",
    "    extensions = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_extension = os.path.splitext(file)[1]\n",
    "            if file_extension not in extensions:\n",
    "                extensions.append(file_extension)\n",
    "        print(f\"Unique files in {root}: {extensions}\")\n",
    "        print(\"-\"*80)\n",
    "\n",
    "folder_path = 'original_images'\n",
    "check_unique_file_formats(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9t74CVrpi00O"
   },
   "source": [
    "##### Unique Images pixel found inside every folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0pLD4_SQi00P"
   },
   "outputs": [],
   "source": [
    "# checking the unique images size\n",
    "def check_image_size(folder_path):\n",
    "    size = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            image_path = os.path.join(root, file)\n",
    "            with Image.open(image_path) as img:\n",
    "                image_size = img.size\n",
    "            if image_size not in size:\n",
    "                size.append(image_size)\n",
    "\n",
    "        print(f\"Unique image size in {root}: {size}\")\n",
    "        print(\"-\"*80)\n",
    "\n",
    "folder_path = 'original_images'\n",
    "check_image_size(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqzuEAH6i00P"
   },
   "source": [
    "##### Unique type of Image file size found inside different folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mN5bTRGVi00P"
   },
   "outputs": [],
   "source": [
    "# Set your directory path\n",
    "base_path = \"original_images\"\n",
    "\n",
    "file_data = []\n",
    "\n",
    "for root, dirs, files in os.walk(base_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        try:\n",
    "            size_kb = os.path.getsize(file_path) / 1024\n",
    "            file_data.append({\n",
    "                \"file_name\": file,\n",
    "                \"folder\": os.path.relpath(root, base_path),\n",
    "                \"size_kb\": round(size_kb, 2)\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(file_data)\n",
    "\n",
    "# Sort by size to detect anomalies\n",
    "df_sorted = df.sort_values(by=\"size_kb\", ascending=False)\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9aQsJOBEi00P"
   },
   "outputs": [],
   "source": [
    "print(\"Unique File Sizes (KB):\")\n",
    "print(df[\"size_kb\"].unique())\n",
    "print(\"Total Files Scanned:\", len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzO4lWmai00Q"
   },
   "source": [
    "##### Algorithm to detect if there are actual faces in the images or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pvlMS5ARi00Q"
   },
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ‚úÖ Initialize MTCNN face detector\n",
    "mtcnn = MTCNN(keep_all=True)\n",
    "folder_path = 'original_images'\n",
    "no_face_images = []\n",
    "\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in tqdm(files):\n",
    "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            file_path = os.path.join(root, file)\n",
    "\n",
    "            try:\n",
    "                img = Image.open(file_path).convert('RGB')\n",
    "                boxes, _ = mtcnn.detect(img)\n",
    "                if boxes is None:\n",
    "                    no_face_images.append(file_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error processing {file_path}: {e}\")\n",
    "                no_face_images.append(file_path)\n",
    "\n",
    "if len(no_face_images) == 0:\n",
    "    print(\"‚úÖ All images have faces.\")\n",
    "else:\n",
    "    print(f\"Found {len(no_face_images)} images with NO faces:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sy0oRDzFi00Q"
   },
   "outputs": [],
   "source": [
    "# Save\n",
    "pd.DataFrame(no_face_images, columns=['FilePath']).to_csv('no_face_images.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LbJAlB5Gi00Q"
   },
   "outputs": [],
   "source": [
    "# Load\n",
    "no_face_images = pd.read_csv('no_face_images.csv')\n",
    "no_face_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HcgOsbqIi00Q"
   },
   "outputs": [],
   "source": [
    "no_face_images_list = no_face_images['FilePath'].tolist()\n",
    "random30 = random.sample(no_face_images_list, min(30, len(no_face_images_list)))\n",
    "plt.figure(figsize=(15,10))\n",
    "for index, file_path in enumerate(random30):\n",
    "    plt.subplot(6, 5, index+1)\n",
    "    img = Image.open(file_path)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GF8Ens_Soomf"
   },
   "source": [
    "##  Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7v_ESjsspbW7"
   },
   "outputs": [],
   "source": [
    "# Chart - 1 visualization code\n",
    "def plot_class_distribution(directory, title):\n",
    "    classes = os.listdir(directory)\n",
    "    counts = [len(os.listdir(os.path.join(directory, cls))) for cls in classes]\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(classes, counts, color='skyblue')\n",
    "    plt.xlabel('Emotion Classes')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_class_distribution(train_data_dir, 'Training Set: Class Distribution')\n",
    "plot_class_distribution(validation_data_dir, 'Validation Set: Class Distribution')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Building & Training our Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hd1sG-qbi00S"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Flatten, Dense,\n",
    "                                     Dropout, BatchNormalization, Rescaling,\n",
    "                                     RandomFlip, RandomRotation, RandomZoom)\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S4C8f4hGi00S"
   },
   "outputs": [],
   "source": [
    "# importing libraries for building the model\n",
    "train_dir = 'preprocessed_images/train'\n",
    "val_dir = 'preprocessed_images/validation'\n",
    "model_save_path = 'cnn_custom_first_model.keras'\n",
    "\n",
    "class_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "IMG_SIZE = (48, 48)\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UhsPm2rOi00S"
   },
   "outputs": [],
   "source": [
    "train_dir = 'preprocessed_images/train'\n",
    "val_dir = 'preprocessed_images/validation'\n",
    "model_save_path = 'cnn_custom_first_model.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1xMEMX8i00T"
   },
   "outputs": [],
   "source": [
    "class_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "IMG_SIZE = (48, 48)\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "obgzjTS9i00T"
   },
   "outputs": [],
   "source": [
    "# ‚úÖ Load datasets\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# ‚úÖ Prefetch for performance\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "data_augmentation = Sequential([\n",
    "    Rescaling(1./255),\n",
    "    RandomFlip(\"horizontal\"),\n",
    "    RandomRotation(0.1),\n",
    "    RandomZoom(0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GyPa2DLBi00U"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    tf.keras.Input(shape=(48, 48, 1)),\n",
    "\n",
    "    # ‚úÖ Data Augmentation Layer\n",
    "    data_augmentation,\n",
    "\n",
    "    # ‚úÖ Block 1\n",
    "    Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    # ‚úÖ Block 2\n",
    "    Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    # ‚úÖ Block 3\n",
    "    Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    # ‚úÖ Fully Connected Layer\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    # ‚úÖ Output Layer\n",
    "    Dense(7, activation='softmax', dtype='float32')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Atk_yxbi00V"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        patience=10,\n",
    "        monitor='val_loss',\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath=model_save_path,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5RhJA_a1i00V"
   },
   "outputs": [],
   "source": [
    "# ‚úÖ Predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in val_ds:\n",
    "    preds = model.predict(images)\n",
    "    y_true.extend(tf.argmax(labels, axis=1).numpy())\n",
    "    y_pred.extend(tf.argmax(preds, axis=1).numpy())\n",
    "\n",
    "# ‚úÖ Classification Report\n",
    "print(\"\\nüìã Classification Report:\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArJBuiUVfxKd"
   },
   "source": [
    "#### Explain the ML Model used and it's performance using Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqD5ZohzfxKe"
   },
   "outputs": [],
   "source": [
    "# Visualizing evaluation Metric Score chart\n",
    "# ‚úÖ Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "3RnN4peoiCZX",
    "x71ZqKXriCWQ",
    "7hBIi_osiCS2",
    "JlHwYmJAmNHm",
    "35m5QtbWiB9F",
    "PoPl-ycgm1ru",
    "H0kj-8xxnORC",
    "dauF4eBmngu3",
    "bKJF3rekwFvQ",
    "MSa1f5Uengrz",
    "GF8Ens_Soomf",
    "0wOQAZs5pc--",
    "lQ7QKXXCp7Bj",
    "VfCC591jGiD4",
    "OB4l2ZhMeS1U",
    "ArJBuiUVfxKd",
    "dJ2tPlVmpsJ0",
    "JWYfwnehpsJ1",
    "Fze-IPXLpx6K",
    "7AN1z2sKpx6M",
    "cBFFvTBNJzUa",
    "-Kee-DAl2viO"
   ],
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
