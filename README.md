# ğŸ§  SentioVision
### Real-Time Facial Emotion Recognition using Deep Learning
<br><br>

## ğŸ” About the Project
**SentioVision** is a real-time **facial emotion recognition system** that identifies human emotions from facial expressions using deep learning.  
The project showcases both **foundational CNN design** and **modern transfer learning techniques** for improved accuracy and robustness.

### ğŸ”§ Core Approaches
* ğŸ§  **Custom CNN** built from scratch to understand fundamentals  
* âš¡ **EfficientNet (Transfer Learning)** for better generalization and performance
<br><br>

### ğŸ˜ƒ Emotion Classes
> ğŸ˜  Angry â€¢ ğŸ˜¢ Sad â€¢ ğŸ˜„ Happy â€¢ ğŸ˜¨ Fear â€¢ ğŸ˜ Neutral â€¢ ğŸ¤¢ Disgust â€¢ ğŸ˜² Surprise
<br><br>

This project bridges **theory and practice**, making it suitable for **learning, experimentation, and real-world demos**.
<br><br>

## ğŸ¯ Potential Applications
* ğŸ§˜ Mental health & emotion monitoring  
* ğŸ›ï¸ Customer feedback and sentiment analysis  
* ğŸ¤– Humanâ€“Computer Interaction (HCI) systems
<br><br>

## ğŸ“˜ Project Overview
| Notebook | Description |
|--------|-------------|
| `FER_Code.ipynb` | CNN implemented from scratch (baseline model) |
| `FER_Code_EfficientNet.ipynb` | EfficientNet-based transfer learning model |
| `webcam.ipynb` | Real-time emotion detection using webcam |


> **Note:**  
> Webcam detection requires a trained model.  
> * Use the **pre-trained model** at `models/emotion_model.keras`, **or**  
> * Train your own model using one of the training notebooks.
<br><br>

## ğŸ§© Dataset Setup (FER2013)
1. Download the **FER2013 dataset** from Kaggle  
2. Create a folder named `original_images` in the project root  
3. Inside it, create `train/` and `test/` directories  
4. Place images accordingly  
<br>


```
original_images/
â”œâ”€â”€ train/
â””â”€â”€ test/
```

<br><br>

## â–¶ï¸ Usage Guide

### âœ… Option 1: Use Pre-trained Model
1. Ensure `models/emotion_model.keras` exists  
2. Run `webcam.ipynb`  
3. Start real-time emotion recognition  

### ğŸ› ï¸ Option 2: Train Your Own Model
1. Run:  
   * `FER_Code.ipynb` **(CNN)**  
   * **or** `FER_Code_EfficientNet.ipynb` **(EfficientNet)**  
2. Best model is automatically saved using callbacks  
3. Model is stored as `models/emotion_model.keras`  
4. Run `webcam.ipynb` for live detection  
<br>

> âš ï¸ **Warning:**  
> Training multiple notebooks without renaming the model file will overwrite the previous model.
<br><br>

## ğŸ“‚ Project Structure
```
emotion_recognition_project/
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ FER_Code.ipynb
â”‚   â”œâ”€â”€ FER_Code_EfficientNet.ipynb
â”‚   â””â”€â”€ webcam.ipynb
â”œâ”€â”€ models/
â”‚   â””â”€â”€ emotion_model.keras
â”œâ”€â”€ original_images/
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ test/
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ banner.png
â”‚   â””â”€â”€ demo.gif
â””â”€â”€ README.md
```


<br><br>

## ğŸ“¸ Demo
<p align="center">
  <img src="assets/demo.gif" alt="Real-time Emotion Detection Demo" width="600"/>
</p>
<br><br>

<h2>ğŸ“¦ Installation &amp; Requirements</h2>

<pre><code>pip install tensorflow keras opencv-python matplotlib seaborn pillow numpy pandas tqdm scikit-learn facenet-pytorch
</code></pre>

<br><br>

<h2>ğŸ§  Notes for Beginners</h2>

<ul>
  <li><b>CNN layers (Conv2D, MaxPooling2D)</b> â†’ used in scratch model</li>
  <li><b>EfficientNet</b> â†’ required only for transfer learning</li>
  <li><b>OpenCV + load_model</b> â†’ used in webcam inference</li>
  <li><b>MTCNN</b> â†’ optional face detection before emotion prediction</li>
</ul>

<br><br>

<h2>ğŸ“„ License</h2>

<p>
This project is open for <b>learning, research, and experimentation</b>.<br>
Feel free to modify and adapt it.
</p>

<br><br>

<h2>ğŸ¤ Contributing</h2>

<p>Contributions are welcome ğŸš€</p>

<ul>
  <li>Report bugs or request features via Issues</li>
  <li>Submit Pull Requests for improvements</li>
  <li>Share ideas to improve accuracy or performance</li>
</ul>

<br><br>

<p align="center">
  <b>â­ If you find this project helpful, consider starring the repository!</b>
</p>
